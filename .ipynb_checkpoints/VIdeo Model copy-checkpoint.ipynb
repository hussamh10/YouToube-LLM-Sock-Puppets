{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_desc = np.zeros(768)\n",
    "empty_title = np.zeros(768)\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, uid): \n",
    "        self.uid = uid\n",
    "        if uid not in video_db:\n",
    "            self.title, self.tags, self.description, self.category, self.channel_title = None, None, None, None, None\n",
    "            self.title_emb, self.tags_emb, self.description_emb = empty_title, [], empty_desc\n",
    "            return\n",
    "\n",
    "        vs = video_db[uid]['snippet']\n",
    "        self.title = vs['title']\n",
    "        self.tags = vs.get('tags', [])\n",
    "        self.description = vs['description']\n",
    "        self.category = vs['categoryId']\n",
    "        self.channel_title = vs['channelTitle']\n",
    "        \n",
    "        self.title_emb = video_db[uid]['embeddings']['title']\n",
    "        self.tags_emb = video_db[uid]['embeddings']['tags']\n",
    "        self.description_emb = video_db[uid]['embeddings']['description']\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.title is None:\n",
    "            return 'Video not found'\n",
    "        return self.title\n",
    "    \n",
    "    def __str__(self):\n",
    "        if self.title is None:\n",
    "            return 'Video not found'\n",
    "        return self.title\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.uid)\n",
    "    \n",
    "def get_id(url):\n",
    "    if len(url.split('v=')) <= 1:\n",
    "        return None\n",
    "    url = url.split('v=')[1]\n",
    "    url = url.split('&')[0]\n",
    "    return url\n",
    "\n",
    "def decode_upnext(urls):\n",
    "    urls = eval(urls.decode('utf-8'))\n",
    "    ids = []\n",
    "    for u in urls:\n",
    "        ids.append(get_id(u))\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = pd.read_pickle('all_sessions')\n",
    "video_db = pd.read_pickle('video-dump-with-embeddings+transcript')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25f6a418e594f9a8cf3b7e9c4003b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6762 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>upnext</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>489B7RNudAQ</td>\n",
       "      <td>[ZOZyo6YOAu4, VtYi8AR11WM, Q32BGQmVLJ0, h1BsKI...</td>\n",
       "      <td>Q32BGQmVLJ0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jnXeE4TY2so</td>\n",
       "      <td>[MeH-4wEuvZs, h1BsKIP4uYM, dqbyJIKLxok, VX4n8w...</td>\n",
       "      <td>HtyVbMZegn4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NQPNRwpGWXc</td>\n",
       "      <td>[2PopspP_DbI, VPrrIGxjubI, 4s2ynUAJ5ZU, dEk8Hb...</td>\n",
       "      <td>VPrrIGxjubI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8tsnuvfMmtc</td>\n",
       "      <td>[4iYl9oSjffQ, mTHedRdHJgk, aeWyp2vXxqA, 6S7VkI...</td>\n",
       "      <td>aeWyp2vXxqA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LcW4MCa5YCQ</td>\n",
       "      <td>[-TgFz3qmE9U, 9scfWN6aXaU, O7VaXlMvAvk, h1BsKI...</td>\n",
       "      <td>z0Xpye7Ltlo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         video                                             upnext     selected\n",
       "0  489B7RNudAQ  [ZOZyo6YOAu4, VtYi8AR11WM, Q32BGQmVLJ0, h1BsKI...  Q32BGQmVLJ0\n",
       "1  jnXeE4TY2so  [MeH-4wEuvZs, h1BsKIP4uYM, dqbyJIKLxok, VX4n8w...  HtyVbMZegn4\n",
       "2  NQPNRwpGWXc  [2PopspP_DbI, VPrrIGxjubI, 4s2ynUAJ5ZU, dEk8Hb...  VPrrIGxjubI\n",
       "3  8tsnuvfMmtc  [4iYl9oSjffQ, mTHedRdHJgk, aeWyp2vXxqA, 6S7VkI...  aeWyp2vXxqA\n",
       "4  LcW4MCa5YCQ  [-TgFz3qmE9U, 9scfWN6aXaU, O7VaXlMvAvk, h1BsKI...  z0Xpye7Ltlo"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single Step Data (only access to this video)\n",
    "ss_session = []\n",
    "for session in tqdm(sessions):\n",
    "    for video, next_video, in zip(session[:-1], session[1:]):\n",
    "        video['selected'] = next_video['url']\n",
    "        ss_session.append(video)\n",
    "\n",
    "\n",
    "data = pd.DataFrame(ss_session)\n",
    "data['url'] = data['url'].apply(get_id)\n",
    "data['selected'] = data['selected'].apply(get_id)\n",
    "data['upnext_content'] = data['upnext_content'].apply(decode_upnext)\n",
    "data = data[['url', 'upnext_content', 'selected']]\n",
    "data.columns = ['video', 'upnext', 'selected']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c3999536964d0e86901bddb3e9fe95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_sessions = []\n",
    "ss_sessions = data.to_dict('records')\n",
    "\n",
    "for session in tqdm(ss_sessions):\n",
    "    video_session = {}\n",
    "    v = Video(session['video'])\n",
    "    video_session['video'] = Video(session['video'])\n",
    "    video_session['upnext'] = []\n",
    "    for upnext in session['upnext']:\n",
    "        video_session['upnext'].append(Video(upnext))\n",
    "    video_session['selected'] = Video(session['selected'])\n",
    "    video_sessions.append(video_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trims(X, Y, l=15):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    indices = np.where(Y == 0)[0]\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    indices = indices[:len(Y) - l]\n",
    "    X = np.delete(X, indices, axis=0)\n",
    "    Y = np.delete(Y, indices, axis=0)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi label output\n",
    "X = []\n",
    "Y = []\n",
    "ss = []\n",
    "for session in video_sessions:\n",
    "    x = []\n",
    "    y = []\n",
    "    if session['selected'].title == None:\n",
    "        continue\n",
    "\n",
    "    if len(session['upnext']) >= 15:\n",
    "        x.append(session['video'].title_emb)\n",
    "\n",
    "        ss.append(session)\n",
    "        selected = session['selected'].title\n",
    "        upnext = session['upnext']\n",
    "        for video in session['upnext']:\n",
    "            if video.title == selected:\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)\n",
    "\n",
    "            x.append(video.title_emb)\n",
    "        x, y = trims(x, y)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 768), (5686, 15))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 04:11:32.803284: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-20 04:11:32.803346: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-20 04:11:34.026038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-06-20 04:11:34.026100: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-20 04:11:34.026146: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (toutatis): /proc/driver/nvidia/version does not exist\n",
      "2023-06-20 04:11:34.026410: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SGD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.4\u001b[39m))\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m15\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 14\u001b[0m sgd \u001b[38;5;241m=\u001b[39m \u001b[43mSGD\u001b[49m(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SGD' is not defined"
     ]
    }
   ],
   "source": [
    "# train cnn model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(8, 8), activation='relu', input_shape=(16, 768, 1)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "45/45 [==============================] - 16s 341ms/step - loss: 2.4097 - Accuracy: 0.3102\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 2.3075 - Accuracy: 0.3480\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 2.3360 - Accuracy: 0.3421\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 15s 343ms/step - loss: 2.2853 - Accuracy: 0.3558\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 2.4526 - Accuracy: 0.3428\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 2.2779 - Accuracy: 0.3558\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 2.2488 - Accuracy: 0.3556\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 2.3698 - Accuracy: 0.3262\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 2.6596 - Accuracy: 0.3278\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 16s 345ms/step - loss: 2.2561 - Accuracy: 0.3549\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 2.3293 - Accuracy: 0.3421\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 16s 348ms/step - loss: 2.3810 - Accuracy: 0.3349\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 2.2490 - Accuracy: 0.3544\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 2.6563 - Accuracy: 0.3414\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 15s 337ms/step - loss: 2.2579 - Accuracy: 0.3556\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 2.2594 - Accuracy: 0.3558\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 2.5535 - Accuracy: 0.3160\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 2.2428 - Accuracy: 0.3558\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 15s 337ms/step - loss: 2.2353 - Accuracy: 0.3558\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 2.2495 - Accuracy: 0.3519\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 2.4137 - Accuracy: 0.3368\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 2.2333 - Accuracy: 0.3558\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 15s 337ms/step - loss: 2.2312 - Accuracy: 0.3558\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 2.2306 - Accuracy: 0.3558\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 2.2312 - Accuracy: 0.3558\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 2.2319 - Accuracy: 0.3558\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 2.2440 - Accuracy: 0.3547\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 2.3575 - Accuracy: 0.3123\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 3.4704 - Accuracy: 0.2575\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 2.3062 - Accuracy: 0.3516\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 2.2562 - Accuracy: 0.3549\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 16s 345ms/step - loss: 2.2564 - Accuracy: 0.3544\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 2.3887 - Accuracy: 0.3371\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 16s 348ms/step - loss: 2.2311 - Accuracy: 0.3558\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 2.2294 - Accuracy: 0.3558\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 15s 344ms/step - loss: 2.2300 - Accuracy: 0.3558\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 2.2290 - Accuracy: 0.3558\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 2.2288 - Accuracy: 0.3558\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 2.2296 - Accuracy: 0.3558\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 15s 337ms/step - loss: 2.2293 - Accuracy: 0.3558\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 2.2298 - Accuracy: 0.3558\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 15s 335ms/step - loss: 2.2293 - Accuracy: 0.3558\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 2.2310 - Accuracy: 0.3558\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 15s 337ms/step - loss: 2.2297 - Accuracy: 0.3558\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 2.2296 - Accuracy: 0.3558\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 16s 349ms/step - loss: 2.2401 - Accuracy: 0.3546\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 2.2806 - Accuracy: 0.3473\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 2.3678 - Accuracy: 0.3364\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 15s 337ms/step - loss: 2.2331 - Accuracy: 0.3558\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 2.2300 - Accuracy: 0.3558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73621f7a60>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train neural network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(6400, activation='relu', input_dim=12288))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(3200, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1600, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(800, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=sgd,\n",
    "                metrics=['Accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 139ms/step - loss: 2.2189 - Accuracy: 0.3615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2189486026763916, 0.3614627420902252]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_max = np.argmax(y_test, axis=1)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_max = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29043600562587907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test_max, y_pred_max, average='micro'))\n",
    "\n",
    "# # recall and precision\n",
    "# from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "# print(recall_score(y_test, y_pred))\n",
    "# print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/data/hussam/sparta/youtube-sim/VIdeo Model copy.ipynb Cell 43\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btoutatis.cs.uiowa.edu/home/data/hussam/sparta/youtube-sim/VIdeo%20Model%20copy.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btoutatis.cs.uiowa.edu/home/data/hussam/sparta/youtube-sim/VIdeo%20Model%20copy.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m roc_curve, auc\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btoutatis.cs.uiowa.edu/home/data/hussam/sparta/youtube-sim/VIdeo%20Model%20copy.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m fpr, tpr, thresholds \u001b[39m=\u001b[39m roc_curve(y_test, y_pred)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btoutatis.cs.uiowa.edu/home/data/hussam/sparta/youtube-sim/VIdeo%20Model%20copy.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m roc_auc \u001b[39m=\u001b[39m auc(fpr, tpr)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btoutatis.cs.uiowa.edu/home/data/hussam/sparta/youtube-sim/VIdeo%20Model%20copy.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m5\u001b[39m))\n",
      "File \u001b[0;32m/home/data/hussam/miniconda3/envs/jup/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m     \u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[39m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[1;32m    993\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[1;32m    994\u001b[0m     )\n\u001b[1;32m    996\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m/home/data/hussam/miniconda3/envs/jup/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:749\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    747\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    748\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[0;32m--> 749\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[1;32m    751\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    752\u001b[0m y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: multilabel-indicator format is not supported"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "        lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy',\n",
    "        lw=2, linestyle='--')  \n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('AUC')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3079"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(X_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11928269192020956"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate f1score\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, m.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jup",
   "language": "python",
   "name": "jup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 16:12:16.405220: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-03 16:12:16.842559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-03 16:12:20.135938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46692 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-08-03 16:12:20.136500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46692 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('../../data/datasets/raw-video-level-watches')\n",
    "videos = pd.read_pickle('../../data/videos_raw_metadata')\n",
    "title_embeddings = pd.read_pickle('../../data/embeddings/title-autoencoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(vec, element, length=15):\n",
    "    #  a vector to length and keep the element\n",
    "    if len(vec) > length:\n",
    "        vec = vec[:length]\n",
    "    if element not in vec:\n",
    "        vec = vec[:-1] + [element]\n",
    "\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PX = []\n",
    "SX = []\n",
    "Y = []\n",
    "for watch in df:\n",
    "    playing = watch['playing']\n",
    "    selected = watch['selected']\n",
    "    suggesteds = watch['upnext']\n",
    "\n",
    "    suggesteds = trim(suggesteds, selected)\n",
    "    \n",
    "    if playing not in videos or selected not in videos or any([s not in videos for s in suggesteds]):\n",
    "        continue\n",
    "\n",
    "    # i = []\n",
    "\n",
    "    # for s in suggesteds:\n",
    "    #     if s == selected:\n",
    "    #         i.append(1)\n",
    "    #     else:\n",
    "    #         i.append(0)\n",
    "\n",
    "    \n",
    "    if len(suggesteds) < 15:\n",
    "        continue\n",
    "    \n",
    "    playing = title_embeddings[videos[playing]['snippet']['title']]\n",
    "    y = title_embeddings[videos[selected]['snippet']['title']]\n",
    "    suggesteds = [title_embeddings[videos[s]['snippet']['title']] for s in suggesteds]\n",
    "\n",
    "    # suggesteds = list(np.array(suggesteds).flatten())   \n",
    "\n",
    "    PX.append(playing)\n",
    "    SX.append(suggesteds)\n",
    "    Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SX[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssx = []\n",
    "\n",
    "for i in range(15):\n",
    "    ssx.append([])\n",
    "\n",
    "\n",
    "for sx in SX:\n",
    "    for i in range(15):\n",
    "        sx[i] = np.array(sx[i])\n",
    "        sx[i] = sx[i].reshape(128)\n",
    "        ssx[i].append(sx[i])\n",
    "px = []\n",
    "\n",
    "for p in PX:\n",
    "    p = np.array(p)\n",
    "    p = p.reshape(128)\n",
    "    px.append(p)\n",
    "\n",
    "yy = []\n",
    "\n",
    "for y in Y:\n",
    "    y = np.array(y)\n",
    "    y = y.reshape(128)\n",
    "    yy.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5023, 5023)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(px), len(ssx[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested inputs\n",
      "suggested layers\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Concatenate, Input\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "playing_input = Input(shape=(128))\n",
    "suggested_inputs = []\n",
    "\n",
    "for _ in range(15):\n",
    "    suggested_layer = Input(shape=(128))\n",
    "    suggested_inputs.append(suggested_layer)\n",
    "\n",
    "print('suggested inputs')\n",
    "\n",
    "playing_layer = Dense(64, activation='relu')(playing_input)\n",
    "suggested_layers = []\n",
    "for sg in suggested_inputs:\n",
    "    sg_layer = Dense(64, activation='relu')(sg)\n",
    "    sg_drop = Dropout(0.2)(sg_layer)\n",
    "    suggested_layers.append()\n",
    "\n",
    "print('suggested layers')\n",
    "\n",
    "inputs = [playing_input] + suggested_inputs\n",
    "\n",
    "merged = Concatenate(axis=1)([playing_layer] + suggested_layers)\n",
    "dense1 = Dense(512, activation='relu')(merged)\n",
    "dp2 = Dropout(0.3)(dense1)\n",
    "output = Dense(128, activation='tanh')(dp2)\n",
    "# dense2 = keras.layers.Dense(6000, activation='sigmoid')(dense1)\n",
    "# output = keras.layers.Dense(5063, activation='tanh')(dense2)\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='cosine_similarity',\n",
    "                optimizer='adam',\n",
    "                metrics='cosine_similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "px = np.array(px)\n",
    "ssx = [np.array(s) for s in ssx]\n",
    "yy = np.array(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "y = yy\n",
    "sx = ssx\n",
    "\n",
    "size = len(y)\n",
    "test_size = int(size * 0.2)\n",
    "indexes = list(range(size))\n",
    "test_indexes = sample(indexes, test_size)\n",
    "\n",
    "pxtrain, pxtest, ytrain, ytest = [], [], [], []\n",
    "sxtrain = [[] for i in sx]\n",
    "sxtest = [[] for i in sx]\n",
    "\n",
    "for i in indexes:\n",
    "    if i in test_indexes:\n",
    "        pxtest.append(px[i])\n",
    "        ytest.append(y[i])\n",
    "        for j in range(15):\n",
    "            sxtest[j].append(sx[j][i])\n",
    "    else:\n",
    "        pxtrain.append(px[i])\n",
    "        ytrain.append(y[i])\n",
    "        for j in range(15):\n",
    "            sxtrain[j].append(sx[j][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsmhabib/.local/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/63 [..............................] - ETA: 47s - loss: 0.0137 - cosine_similarity: -0.0137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 16:13:08.413865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 6s 77ms/step - loss: -0.2000 - cosine_similarity: 0.2000 - val_loss: -0.3030 - val_cosine_similarity: 0.3030\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.3715 - cosine_similarity: 0.3715 - val_loss: -0.3758 - val_cosine_similarity: 0.3758\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 5s 77ms/step - loss: -0.4583 - cosine_similarity: 0.4583 - val_loss: -0.4014 - val_cosine_similarity: 0.4014\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.5146 - cosine_similarity: 0.5146 - val_loss: -0.4084 - val_cosine_similarity: 0.4084\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.5580 - cosine_similarity: 0.5580 - val_loss: -0.4126 - val_cosine_similarity: 0.4126\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.5935 - cosine_similarity: 0.5935 - val_loss: -0.4104 - val_cosine_similarity: 0.4104\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.6254 - cosine_similarity: 0.6254 - val_loss: -0.4116 - val_cosine_similarity: 0.4116\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 5s 74ms/step - loss: -0.6502 - cosine_similarity: 0.6502 - val_loss: -0.4052 - val_cosine_similarity: 0.4052\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 5s 74ms/step - loss: -0.6716 - cosine_similarity: 0.6716 - val_loss: -0.4034 - val_cosine_similarity: 0.4034\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 5s 74ms/step - loss: -0.6901 - cosine_similarity: 0.6901 - val_loss: -0.3990 - val_cosine_similarity: 0.3990\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 5s 79ms/step - loss: -0.7062 - cosine_similarity: 0.7062 - val_loss: -0.3948 - val_cosine_similarity: 0.3948\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.7181 - cosine_similarity: 0.7181 - val_loss: -0.3941 - val_cosine_similarity: 0.3941\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.7307 - cosine_similarity: 0.7307 - val_loss: -0.3897 - val_cosine_similarity: 0.3897\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 5s 74ms/step - loss: -0.7409 - cosine_similarity: 0.7409 - val_loss: -0.3893 - val_cosine_similarity: 0.3893\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.7492 - cosine_similarity: 0.7492 - val_loss: -0.3862 - val_cosine_similarity: 0.3862\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.7558 - cosine_similarity: 0.7558 - val_loss: -0.3844 - val_cosine_similarity: 0.3844\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.7617 - cosine_similarity: 0.7617 - val_loss: -0.3844 - val_cosine_similarity: 0.3844\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.7672 - cosine_similarity: 0.7672 - val_loss: -0.3820 - val_cosine_similarity: 0.3820\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.7737 - cosine_similarity: 0.7737 - val_loss: -0.3800 - val_cosine_similarity: 0.3800\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.7763 - cosine_similarity: 0.7763 - val_loss: -0.3788 - val_cosine_similarity: 0.3788\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.7815 - cosine_similarity: 0.7815 - val_loss: -0.3781 - val_cosine_similarity: 0.3781\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.7852 - cosine_similarity: 0.7852 - val_loss: -0.3751 - val_cosine_similarity: 0.3751\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.7877 - cosine_similarity: 0.7877 - val_loss: -0.3742 - val_cosine_similarity: 0.3742\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.7897 - cosine_similarity: 0.7897 - val_loss: -0.3767 - val_cosine_similarity: 0.3767\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.7944 - cosine_similarity: 0.7944 - val_loss: -0.3757 - val_cosine_similarity: 0.3757\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.7959 - cosine_similarity: 0.7959 - val_loss: -0.3735 - val_cosine_similarity: 0.3735\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.7988 - cosine_similarity: 0.7988 - val_loss: -0.3742 - val_cosine_similarity: 0.3742\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 5s 79ms/step - loss: -0.8023 - cosine_similarity: 0.8023 - val_loss: -0.3736 - val_cosine_similarity: 0.3736\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8030 - cosine_similarity: 0.8030 - val_loss: -0.3718 - val_cosine_similarity: 0.3718\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8049 - cosine_similarity: 0.8049 - val_loss: -0.3700 - val_cosine_similarity: 0.3700\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8070 - cosine_similarity: 0.8070 - val_loss: -0.3700 - val_cosine_similarity: 0.3700\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8084 - cosine_similarity: 0.8084 - val_loss: -0.3708 - val_cosine_similarity: 0.3708\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8092 - cosine_similarity: 0.8092 - val_loss: -0.3705 - val_cosine_similarity: 0.3705\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8104 - cosine_similarity: 0.8104 - val_loss: -0.3701 - val_cosine_similarity: 0.3701\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8115 - cosine_similarity: 0.8115 - val_loss: -0.3692 - val_cosine_similarity: 0.3692\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8139 - cosine_similarity: 0.8139 - val_loss: -0.3672 - val_cosine_similarity: 0.3672\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8154 - cosine_similarity: 0.8154 - val_loss: -0.3642 - val_cosine_similarity: 0.3642\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8158 - cosine_similarity: 0.8158 - val_loss: -0.3679 - val_cosine_similarity: 0.3679\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8185 - cosine_similarity: 0.8185 - val_loss: -0.3669 - val_cosine_similarity: 0.3669\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8180 - cosine_similarity: 0.8180 - val_loss: -0.3650 - val_cosine_similarity: 0.3650\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8189 - cosine_similarity: 0.8189 - val_loss: -0.3661 - val_cosine_similarity: 0.3661\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8203 - cosine_similarity: 0.8203 - val_loss: -0.3644 - val_cosine_similarity: 0.3644\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8212 - cosine_similarity: 0.8212 - val_loss: -0.3658 - val_cosine_similarity: 0.3658\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8217 - cosine_similarity: 0.8217 - val_loss: -0.3639 - val_cosine_similarity: 0.3639\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8223 - cosine_similarity: 0.8223 - val_loss: -0.3648 - val_cosine_similarity: 0.3648\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8242 - cosine_similarity: 0.8242 - val_loss: -0.3636 - val_cosine_similarity: 0.3636\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 5s 79ms/step - loss: -0.8250 - cosine_similarity: 0.8250 - val_loss: -0.3651 - val_cosine_similarity: 0.3651\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8255 - cosine_similarity: 0.8255 - val_loss: -0.3651 - val_cosine_similarity: 0.3651\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8258 - cosine_similarity: 0.8258 - val_loss: -0.3638 - val_cosine_similarity: 0.3638\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 5s 74ms/step - loss: -0.8270 - cosine_similarity: 0.8270 - val_loss: -0.3651 - val_cosine_similarity: 0.3651\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 5s 74ms/step - loss: -0.8279 - cosine_similarity: 0.8279 - val_loss: -0.3625 - val_cosine_similarity: 0.3625\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 5s 74ms/step - loss: -0.8292 - cosine_similarity: 0.8292 - val_loss: -0.3631 - val_cosine_similarity: 0.3631\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8285 - cosine_similarity: 0.8285 - val_loss: -0.3646 - val_cosine_similarity: 0.3646\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8305 - cosine_similarity: 0.8305 - val_loss: -0.3636 - val_cosine_similarity: 0.3636\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8309 - cosine_similarity: 0.8309 - val_loss: -0.3629 - val_cosine_similarity: 0.3629\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8311 - cosine_similarity: 0.8311 - val_loss: -0.3628 - val_cosine_similarity: 0.3628\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8317 - cosine_similarity: 0.8317 - val_loss: -0.3617 - val_cosine_similarity: 0.3617\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 5s 74ms/step - loss: -0.8323 - cosine_similarity: 0.8323 - val_loss: -0.3626 - val_cosine_similarity: 0.3626\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 5s 74ms/step - loss: -0.8326 - cosine_similarity: 0.8326 - val_loss: -0.3616 - val_cosine_similarity: 0.3616\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8337 - cosine_similarity: 0.8337 - val_loss: -0.3638 - val_cosine_similarity: 0.3638\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8321 - cosine_similarity: 0.8321 - val_loss: -0.3609 - val_cosine_similarity: 0.3609\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8338 - cosine_similarity: 0.8338 - val_loss: -0.3612 - val_cosine_similarity: 0.3612\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8335 - cosine_similarity: 0.8335 - val_loss: -0.3614 - val_cosine_similarity: 0.3614\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8361 - cosine_similarity: 0.8361 - val_loss: -0.3609 - val_cosine_similarity: 0.3609\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 5s 74ms/step - loss: -0.8350 - cosine_similarity: 0.8350 - val_loss: -0.3633 - val_cosine_similarity: 0.3633\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 5s 74ms/step - loss: -0.8346 - cosine_similarity: 0.8346 - val_loss: -0.3608 - val_cosine_similarity: 0.3608\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 5s 74ms/step - loss: -0.8362 - cosine_similarity: 0.8362 - val_loss: -0.3611 - val_cosine_similarity: 0.3611\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8365 - cosine_similarity: 0.8365 - val_loss: -0.3620 - val_cosine_similarity: 0.3620\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8372 - cosine_similarity: 0.8372 - val_loss: -0.3617 - val_cosine_similarity: 0.3617\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8374 - cosine_similarity: 0.8374 - val_loss: -0.3616 - val_cosine_similarity: 0.3616\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8385 - cosine_similarity: 0.8385 - val_loss: -0.3615 - val_cosine_similarity: 0.3615\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8387 - cosine_similarity: 0.8387 - val_loss: -0.3590 - val_cosine_similarity: 0.3590\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 5s 79ms/step - loss: -0.8390 - cosine_similarity: 0.8390 - val_loss: -0.3596 - val_cosine_similarity: 0.3596\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8397 - cosine_similarity: 0.8397 - val_loss: -0.3598 - val_cosine_similarity: 0.3598\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8396 - cosine_similarity: 0.8396 - val_loss: -0.3592 - val_cosine_similarity: 0.3592\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8402 - cosine_similarity: 0.8402 - val_loss: -0.3592 - val_cosine_similarity: 0.3592\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.8407 - cosine_similarity: 0.8407 - val_loss: -0.3594 - val_cosine_similarity: 0.3594\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8415 - cosine_similarity: 0.8415 - val_loss: -0.3596 - val_cosine_similarity: 0.3596\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.8419 - cosine_similarity: 0.8419 - val_loss: -0.3592 - val_cosine_similarity: 0.3592\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8418 - cosine_similarity: 0.8418 - val_loss: -0.3578 - val_cosine_similarity: 0.3578\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8420 - cosine_similarity: 0.8420 - val_loss: -0.3601 - val_cosine_similarity: 0.3601\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8415 - cosine_similarity: 0.8415 - val_loss: -0.3595 - val_cosine_similarity: 0.3595\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8425 - cosine_similarity: 0.8425 - val_loss: -0.3577 - val_cosine_similarity: 0.3577\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: -0.8433 - cosine_similarity: 0.8433 - val_loss: -0.3596 - val_cosine_similarity: 0.3596\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8434 - cosine_similarity: 0.8434 - val_loss: -0.3580 - val_cosine_similarity: 0.3580\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8427 - cosine_similarity: 0.8427 - val_loss: -0.3599 - val_cosine_similarity: 0.3599\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8442 - cosine_similarity: 0.8442 - val_loss: -0.3580 - val_cosine_similarity: 0.3580\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8434 - cosine_similarity: 0.8434 - val_loss: -0.3581 - val_cosine_similarity: 0.3581\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8442 - cosine_similarity: 0.8442 - val_loss: -0.3576 - val_cosine_similarity: 0.3576\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 5s 74ms/step - loss: -0.8448 - cosine_similarity: 0.8448 - val_loss: -0.3570 - val_cosine_similarity: 0.3570\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8444 - cosine_similarity: 0.8444 - val_loss: -0.3578 - val_cosine_similarity: 0.3578\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 5s 79ms/step - loss: -0.8444 - cosine_similarity: 0.8444 - val_loss: -0.3577 - val_cosine_similarity: 0.3577\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8441 - cosine_similarity: 0.8441 - val_loss: -0.3579 - val_cosine_similarity: 0.3579\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8461 - cosine_similarity: 0.8461 - val_loss: -0.3581 - val_cosine_similarity: 0.3581\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8466 - cosine_similarity: 0.8466 - val_loss: -0.3582 - val_cosine_similarity: 0.3582\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8473 - cosine_similarity: 0.8473 - val_loss: -0.3582 - val_cosine_similarity: 0.3582\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8470 - cosine_similarity: 0.8470 - val_loss: -0.3582 - val_cosine_similarity: 0.3582\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8464 - cosine_similarity: 0.8464 - val_loss: -0.3583 - val_cosine_similarity: 0.3583\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8473 - cosine_similarity: 0.8473 - val_loss: -0.3566 - val_cosine_similarity: 0.3566\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 5s 75ms/step - loss: -0.8481 - cosine_similarity: 0.8481 - val_loss: -0.3575 - val_cosine_similarity: 0.3575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb10e372610>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([px] + ssx, yy, epochs=100, batch_size=64, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

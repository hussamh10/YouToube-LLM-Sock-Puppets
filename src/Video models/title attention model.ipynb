{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 16:12:16.405220: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-03 16:12:16.842559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-03 16:12:20.135938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46692 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-08-03 16:12:20.136500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46692 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('../../data/datasets/raw-video-level-watches')\n",
    "videos = pd.read_pickle('../../data/videos_raw_metadata')\n",
    "title_embeddings = pd.read_pickle('../../data/embeddings/title-autoencoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(vec, element, length=15):\n",
    "    #  a vector to length and keep the element\n",
    "    if len(vec) > length:\n",
    "        vec = vec[:length]\n",
    "    if element not in vec:\n",
    "        vec = vec[:-1] + [element]\n",
    "\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PX = []\n",
    "SX = []\n",
    "Y = []\n",
    "for watch in df:\n",
    "    playing = watch['playing']\n",
    "    selected = watch['selected']\n",
    "    suggesteds = watch['upnext']\n",
    "\n",
    "    suggesteds = trim(suggesteds, selected)\n",
    "    \n",
    "    if playing not in videos or selected not in videos or any([s not in videos for s in suggesteds]):\n",
    "        continue\n",
    "\n",
    "    # i = []\n",
    "\n",
    "    # for s in suggesteds:\n",
    "    #     if s == selected:\n",
    "    #         i.append(1)\n",
    "    #     else:\n",
    "    #         i.append(0)\n",
    "\n",
    "    \n",
    "    if len(suggesteds) < 15:\n",
    "        continue\n",
    "    \n",
    "    playing = title_embeddings[videos[playing]['snippet']['title']]\n",
    "    y = title_embeddings[videos[selected]['snippet']['title']]\n",
    "    suggesteds = [title_embeddings[videos[s]['snippet']['title']] for s in suggesteds]\n",
    "\n",
    "    # suggesteds = list(np.array(suggesteds).flatten())   \n",
    "\n",
    "    PX.append(playing)\n",
    "    SX.append(suggesteds)\n",
    "    Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SX[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssx = []\n",
    "\n",
    "for i in range(15):\n",
    "    ssx.append([])\n",
    "\n",
    "\n",
    "for sx in SX:\n",
    "    for i in range(15):\n",
    "        sx[i] = np.array(sx[i])\n",
    "        sx[i] = sx[i].reshape(128)\n",
    "        ssx[i].append(sx[i])\n",
    "px = []\n",
    "\n",
    "for p in PX:\n",
    "    p = np.array(p)\n",
    "    p = p.reshape(128)\n",
    "    px.append(p)\n",
    "\n",
    "yy = []\n",
    "\n",
    "for y in Y:\n",
    "    y = np.array(y)\n",
    "    y = y.reshape(128)\n",
    "    yy.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5023, 5023)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(px), len(ssx[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested inputs\n",
      "suggested layers\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Concatenate, Input\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "playing_input = Input(shape=(128))\n",
    "suggested_inputs = []\n",
    "\n",
    "for _ in range(15):\n",
    "    suggested_layer = Input(shape=(128))\n",
    "    suggested_inputs.append(suggested_layer)\n",
    "\n",
    "print('suggested inputs')\n",
    "\n",
    "playing_layer = Dense(64, activation='relu')(playing_input)\n",
    "suggested_layers = []\n",
    "for sg in suggested_inputs:\n",
    "    sg_layer = Dense(64, activation='relu')(sg)\n",
    "    sg_drop = Dropout(0.2)(sg_layer)\n",
    "    suggested_layers.append(sg_drop)\n",
    "\n",
    "print('suggested layers')\n",
    "\n",
    "inputs = [playing_input] + suggested_inputs\n",
    "\n",
    "merged = Concatenate(axis=1)([playing_layer] + suggested_layers)\n",
    "dense1 = Dense(512, activation='relu')(merged)\n",
    "dp2 = Dropout(0.3)(dense1)\n",
    "output = Dense(128, activation='tanh')(dp2)\n",
    "# dense2 = keras.layers.Dense(6000, activation='sigmoid')(dense1)\n",
    "# output = keras.layers.Dense(5063, activation='tanh')(dense2)\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='cosine_similarity',\n",
    "                optimizer='adam',\n",
    "                metrics='cosine_similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "px = np.array(px)\n",
    "ssx = [np.array(s) for s in ssx]\n",
    "yy = np.array(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "y = yy\n",
    "sx = ssx\n",
    "\n",
    "size = len(y)\n",
    "test_size = int(size * 0.2)\n",
    "indexes = list(range(size))\n",
    "test_indexes = sample(indexes, test_size)\n",
    "\n",
    "pxtrain, pxtest, ytrain, ytest = [], [], [], []\n",
    "sxtrain = [[] for i in sx]\n",
    "sxtest = [[] for i in sx]\n",
    "\n",
    "for i in indexes:\n",
    "    if i in test_indexes:\n",
    "        pxtest.append(px[i])\n",
    "        ytest.append(y[i])\n",
    "        for j in range(15):\n",
    "            sxtest[j].append(sx[j][i])\n",
    "    else:\n",
    "        pxtrain.append(px[i])\n",
    "        ytrain.append(y[i])\n",
    "        for j in range(15):\n",
    "            sxtrain[j].append(sx[j][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.1898 - cosine_similarity: 0.1898 - val_loss: -0.2950 - val_cosine_similarity: 0.2950\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.3537 - cosine_similarity: 0.3537 - val_loss: -0.3743 - val_cosine_similarity: 0.3743\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.4317 - cosine_similarity: 0.4317 - val_loss: -0.4036 - val_cosine_similarity: 0.4036\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.4780 - cosine_similarity: 0.4780 - val_loss: -0.4146 - val_cosine_similarity: 0.4146\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.5135 - cosine_similarity: 0.5135 - val_loss: -0.4172 - val_cosine_similarity: 0.4172\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.5415 - cosine_similarity: 0.5415 - val_loss: -0.4212 - val_cosine_similarity: 0.4212\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.5662 - cosine_similarity: 0.5662 - val_loss: -0.4167 - val_cosine_similarity: 0.4167\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.5879 - cosine_similarity: 0.5879 - val_loss: -0.4150 - val_cosine_similarity: 0.4150\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.6071 - cosine_similarity: 0.6071 - val_loss: -0.4163 - val_cosine_similarity: 0.4163\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.6238 - cosine_similarity: 0.6238 - val_loss: -0.4098 - val_cosine_similarity: 0.4098\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.6359 - cosine_similarity: 0.6359 - val_loss: -0.4109 - val_cosine_similarity: 0.4109\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.6483 - cosine_similarity: 0.6483 - val_loss: -0.4075 - val_cosine_similarity: 0.4075\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.6597 - cosine_similarity: 0.6597 - val_loss: -0.4046 - val_cosine_similarity: 0.4046\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.6703 - cosine_similarity: 0.6703 - val_loss: -0.4006 - val_cosine_similarity: 0.4006\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.6776 - cosine_similarity: 0.6776 - val_loss: -0.4002 - val_cosine_similarity: 0.4002\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.6863 - cosine_similarity: 0.6863 - val_loss: -0.3981 - val_cosine_similarity: 0.3981\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.6937 - cosine_similarity: 0.6937 - val_loss: -0.4001 - val_cosine_similarity: 0.4001\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.6987 - cosine_similarity: 0.6987 - val_loss: -0.3957 - val_cosine_similarity: 0.3957\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7053 - cosine_similarity: 0.7053 - val_loss: -0.3895 - val_cosine_similarity: 0.3895\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 6s 94ms/step - loss: -0.7109 - cosine_similarity: 0.7109 - val_loss: -0.3964 - val_cosine_similarity: 0.3964\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7162 - cosine_similarity: 0.7162 - val_loss: -0.3921 - val_cosine_similarity: 0.3921\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7193 - cosine_similarity: 0.7193 - val_loss: -0.3917 - val_cosine_similarity: 0.3917\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7230 - cosine_similarity: 0.7230 - val_loss: -0.3904 - val_cosine_similarity: 0.3904\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7275 - cosine_similarity: 0.7275 - val_loss: -0.3913 - val_cosine_similarity: 0.3913\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7299 - cosine_similarity: 0.7299 - val_loss: -0.3921 - val_cosine_similarity: 0.3921\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7336 - cosine_similarity: 0.7336 - val_loss: -0.3871 - val_cosine_similarity: 0.3871\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7381 - cosine_similarity: 0.7381 - val_loss: -0.3868 - val_cosine_similarity: 0.3868\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7385 - cosine_similarity: 0.7385 - val_loss: -0.3902 - val_cosine_similarity: 0.3902\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7430 - cosine_similarity: 0.7430 - val_loss: -0.3878 - val_cosine_similarity: 0.3878\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7439 - cosine_similarity: 0.7439 - val_loss: -0.3879 - val_cosine_similarity: 0.3879\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7480 - cosine_similarity: 0.7480 - val_loss: -0.3868 - val_cosine_similarity: 0.3868\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 6s 94ms/step - loss: -0.7488 - cosine_similarity: 0.7488 - val_loss: -0.3870 - val_cosine_similarity: 0.3870\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7497 - cosine_similarity: 0.7497 - val_loss: -0.3854 - val_cosine_similarity: 0.3854\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.7541 - cosine_similarity: 0.7541 - val_loss: -0.3846 - val_cosine_similarity: 0.3846\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7563 - cosine_similarity: 0.7563 - val_loss: -0.3846 - val_cosine_similarity: 0.3846\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7569 - cosine_similarity: 0.7569 - val_loss: -0.3859 - val_cosine_similarity: 0.3859\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7602 - cosine_similarity: 0.7602 - val_loss: -0.3856 - val_cosine_similarity: 0.3856\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 6s 94ms/step - loss: -0.7611 - cosine_similarity: 0.7611 - val_loss: -0.3849 - val_cosine_similarity: 0.3849\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7641 - cosine_similarity: 0.7641 - val_loss: -0.3844 - val_cosine_similarity: 0.3844\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7650 - cosine_similarity: 0.7650 - val_loss: -0.3828 - val_cosine_similarity: 0.3828\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7652 - cosine_similarity: 0.7652 - val_loss: -0.3821 - val_cosine_similarity: 0.3821\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.7658 - cosine_similarity: 0.7658 - val_loss: -0.3825 - val_cosine_similarity: 0.3825\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7691 - cosine_similarity: 0.7691 - val_loss: -0.3816 - val_cosine_similarity: 0.3816\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 6s 94ms/step - loss: -0.7685 - cosine_similarity: 0.7685 - val_loss: -0.3816 - val_cosine_similarity: 0.3816\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7708 - cosine_similarity: 0.7708 - val_loss: -0.3815 - val_cosine_similarity: 0.3815\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7724 - cosine_similarity: 0.7724 - val_loss: -0.3819 - val_cosine_similarity: 0.3819\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7743 - cosine_similarity: 0.7743 - val_loss: -0.3802 - val_cosine_similarity: 0.3802\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7733 - cosine_similarity: 0.7733 - val_loss: -0.3829 - val_cosine_similarity: 0.3829\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7757 - cosine_similarity: 0.7757 - val_loss: -0.3801 - val_cosine_similarity: 0.3801\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.7763 - cosine_similarity: 0.7763 - val_loss: -0.3793 - val_cosine_similarity: 0.3793\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.7770 - cosine_similarity: 0.7770 - val_loss: -0.3819 - val_cosine_similarity: 0.3819\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.7786 - cosine_similarity: 0.7786 - val_loss: -0.3800 - val_cosine_similarity: 0.3800\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7780 - cosine_similarity: 0.7780 - val_loss: -0.3813 - val_cosine_similarity: 0.3813\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7793 - cosine_similarity: 0.7793 - val_loss: -0.3817 - val_cosine_similarity: 0.3817\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7813 - cosine_similarity: 0.7813 - val_loss: -0.3832 - val_cosine_similarity: 0.3832\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7815 - cosine_similarity: 0.7815 - val_loss: -0.3791 - val_cosine_similarity: 0.3791\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7835 - cosine_similarity: 0.7835 - val_loss: -0.3803 - val_cosine_similarity: 0.3803\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 6s 94ms/step - loss: -0.7843 - cosine_similarity: 0.7843 - val_loss: -0.3794 - val_cosine_similarity: 0.3794\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7838 - cosine_similarity: 0.7838 - val_loss: -0.3772 - val_cosine_similarity: 0.3772\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7854 - cosine_similarity: 0.7854 - val_loss: -0.3795 - val_cosine_similarity: 0.3795\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 10s 152ms/step - loss: -0.7869 - cosine_similarity: 0.7869 - val_loss: -0.3783 - val_cosine_similarity: 0.3783\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7873 - cosine_similarity: 0.7873 - val_loss: -0.3806 - val_cosine_similarity: 0.3806\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7886 - cosine_similarity: 0.7886 - val_loss: -0.3783 - val_cosine_similarity: 0.3783\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7882 - cosine_similarity: 0.7882 - val_loss: -0.3798 - val_cosine_similarity: 0.3798\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.7897 - cosine_similarity: 0.7897 - val_loss: -0.3787 - val_cosine_similarity: 0.3787\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7908 - cosine_similarity: 0.7908 - val_loss: -0.3765 - val_cosine_similarity: 0.3765\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 6s 94ms/step - loss: -0.7894 - cosine_similarity: 0.7894 - val_loss: -0.3773 - val_cosine_similarity: 0.3773\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7909 - cosine_similarity: 0.7909 - val_loss: -0.3754 - val_cosine_similarity: 0.3754\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 6s 94ms/step - loss: -0.7913 - cosine_similarity: 0.7913 - val_loss: -0.3785 - val_cosine_similarity: 0.3785\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7933 - cosine_similarity: 0.7933 - val_loss: -0.3745 - val_cosine_similarity: 0.3745\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7925 - cosine_similarity: 0.7925 - val_loss: -0.3789 - val_cosine_similarity: 0.3789\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7946 - cosine_similarity: 0.7946 - val_loss: -0.3764 - val_cosine_similarity: 0.3764\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 6s 94ms/step - loss: -0.7953 - cosine_similarity: 0.7953 - val_loss: -0.3761 - val_cosine_similarity: 0.3761\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7945 - cosine_similarity: 0.7945 - val_loss: -0.3764 - val_cosine_similarity: 0.3764\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7953 - cosine_similarity: 0.7953 - val_loss: -0.3756 - val_cosine_similarity: 0.3756\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.7965 - cosine_similarity: 0.7965 - val_loss: -0.3783 - val_cosine_similarity: 0.3783\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7960 - cosine_similarity: 0.7960 - val_loss: -0.3741 - val_cosine_similarity: 0.3741\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.7976 - cosine_similarity: 0.7976 - val_loss: -0.3770 - val_cosine_similarity: 0.3770\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7973 - cosine_similarity: 0.7973 - val_loss: -0.3759 - val_cosine_similarity: 0.3759\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7985 - cosine_similarity: 0.7985 - val_loss: -0.3751 - val_cosine_similarity: 0.3751\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.7992 - cosine_similarity: 0.7992 - val_loss: -0.3753 - val_cosine_similarity: 0.3753\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.7995 - cosine_similarity: 0.7995 - val_loss: -0.3751 - val_cosine_similarity: 0.3751\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.8000 - cosine_similarity: 0.8000 - val_loss: -0.3749 - val_cosine_similarity: 0.3749\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.8001 - cosine_similarity: 0.8001 - val_loss: -0.3768 - val_cosine_similarity: 0.3768\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.8001 - cosine_similarity: 0.8001 - val_loss: -0.3755 - val_cosine_similarity: 0.3755\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.8008 - cosine_similarity: 0.8008 - val_loss: -0.3769 - val_cosine_similarity: 0.3769\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.8022 - cosine_similarity: 0.8022 - val_loss: -0.3752 - val_cosine_similarity: 0.3752\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.8012 - cosine_similarity: 0.8012 - val_loss: -0.3744 - val_cosine_similarity: 0.3744\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.8004 - cosine_similarity: 0.8004 - val_loss: -0.3750 - val_cosine_similarity: 0.3750\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.8033 - cosine_similarity: 0.8033 - val_loss: -0.3755 - val_cosine_similarity: 0.3755\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.8039 - cosine_similarity: 0.8039 - val_loss: -0.3750 - val_cosine_similarity: 0.3750\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: -0.8042 - cosine_similarity: 0.8042 - val_loss: -0.3746 - val_cosine_similarity: 0.3746\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.8046 - cosine_similarity: 0.8046 - val_loss: -0.3741 - val_cosine_similarity: 0.3741\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.8045 - cosine_similarity: 0.8045 - val_loss: -0.3742 - val_cosine_similarity: 0.3742\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.8025 - cosine_similarity: 0.8025 - val_loss: -0.3735 - val_cosine_similarity: 0.3735\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: -0.8048 - cosine_similarity: 0.8048 - val_loss: -0.3752 - val_cosine_similarity: 0.3752\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: -0.8051 - cosine_similarity: 0.8051 - val_loss: -0.3744 - val_cosine_similarity: 0.3744\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.8058 - cosine_similarity: 0.8058 - val_loss: -0.3738 - val_cosine_similarity: 0.3738\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.8062 - cosine_similarity: 0.8062 - val_loss: -0.3753 - val_cosine_similarity: 0.3753\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: -0.8068 - cosine_similarity: 0.8068 - val_loss: -0.3753 - val_cosine_similarity: 0.3753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fafb475ab20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([px] + ssx, yy, epochs=100, batch_size=64, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

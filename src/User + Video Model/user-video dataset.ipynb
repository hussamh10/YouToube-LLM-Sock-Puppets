{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = pd.read_pickle('../../data/videos_raw_metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 12:48:41.746209: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 12:48:42.217195: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-25 12:48:43.519926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 443 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-08-25 12:48:43.520398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46246 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "watches = pd.read_pickle('../../data/user-level-data')\n",
    "df = pd.read_pickle('../../data/datasets/raw-video-level-watches')\n",
    "title_embeddings = pd.read_pickle('../../data/embeddings/title-autoencoded')\n",
    "title_openai_embeddings = pd.read_pickle('../../data/embeddings/openai-title')\n",
    "tag_embeddings = pd.read_pickle('../../data/embeddings/tag_embeddings.pkl')\n",
    "topic_embeddings = pd.read_pickle('../../data/embeddings/topic_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list(watches.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = users[9]\n",
    "watch = watches[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(watch):\n",
    "    if watch['playing'] == None:\n",
    "        return None\n",
    "    if 'id' in watch['playing']:\n",
    "        playing = watch['playing']['id']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    selected = watch['selected']\n",
    "\n",
    "    suggesteds = []\n",
    "    for s in watch['suggested']:\n",
    "        if s == None:\n",
    "            continue\n",
    "        if 'id' in s:\n",
    "            suggesteds.append(s['id'])\n",
    "\n",
    "    w  = dict()\n",
    "    w['playing'] = playing\n",
    "    w['selected'] = selected\n",
    "    w['suggesteds'] = suggesteds\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_id = dict()\n",
    "for user in users:\n",
    "    watch_id[user] = []\n",
    "    for watch in watches[user]:\n",
    "        w = get_ids(watch)\n",
    "        watch_id[user].append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dict()\n",
    "history_data = dict()\n",
    "h = 0\n",
    "t = 0\n",
    "for user in users:\n",
    "    training_data[user] = []\n",
    "    history_data[user] = []\n",
    "\n",
    "    for watch in watch_id[user]:\n",
    "        if watch == None:\n",
    "            continue\n",
    "        if watch['playing'] == None:\n",
    "            continue\n",
    "        if watch['selected'] == None:\n",
    "            history_data[user].append(watch['playing'])\n",
    "            continue\n",
    "        if watch['suggesteds'] == None:\n",
    "            history_data[user].append(watch['playing'])\n",
    "            continue\n",
    "        if len(watch['suggesteds']) < 10:\n",
    "            history_data[user].append(watch['playing'])\n",
    "            continue\n",
    "\n",
    "        training_data[user].append(watch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = []\n",
    "\n",
    "for user in users:\n",
    "    for watch in training_data[user]:\n",
    "        watch['user'] = user\n",
    "        sessions.append(watch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl.dump(training_data, open('../../data/new_age/training_watches', 'wb'))\n",
    "# pkl.dump(history_data, open('../../data/new_age/history_videos', 'wb'))\n",
    "# pkl.dump(sessions, open('../../data/new_age/sessions', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# title_embeddings = pd.read_pickle('../../data/embeddings/title-autoencoded')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# title_openai_embeddings = pd.read_pickle('../../data/embeddings/openai-title')\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m tag_embeddings \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(\u001b[39m'\u001b[39m\u001b[39m../../data/embeddings/tag_embeddings.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# topic_embeddings = pd.read_pickle('../../data/embeddings/topic_embeddings.pkl')\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# title_embeddings = pd.read_pickle('../../data/embeddings/title-autoencoded')\n",
    "# title_openai_embeddings = pd.read_pickle('../../data/embeddings/openai-title')\n",
    "tag_embeddings = pd.read_pickle('../../data/embeddings/tag_embeddings.pkl')\n",
    "# topic_embeddings = pd.read_pickle('../../data/embeddings/topic_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = list(videos.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_embeddings[vv[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = vv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good-day-atlanta',\n",
       " 'news',\n",
       " 'waga',\n",
       " 'dana fowle',\n",
       " 'fox 5 i-team',\n",
       " 'mikel muffley',\n",
       " 'muffley homes',\n",
       " 'muffley']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos[v]['snippet']['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "# Download a pre-trained FastText model (change the parameters as needed)\n",
    "model_path = fasttext.util.download_model('en', if_exists='ignore')  # 'en' for English\n",
    "\n",
    "# Load the downloaded model\n",
    "model = fasttext.load_model(model_path)\n",
    "\n",
    "# Get embeddings for a word\n",
    "\n",
    "def get_embeddings(word):\n",
    "    return model.get_word_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 13:25:29.047366: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 13:25:29.781902: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-25 13:25:31.435699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1337 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-08-25 13:25:31.436307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46246 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "video_data = pkl.load(open('../../data/new_age/video_data', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77614189a929485ebd9e4e5f5de65a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/524537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ids = videos.keys()\n",
    "for video_id in tqdm(ids):\n",
    "    video = videos[video_id]\n",
    "\n",
    "    if 'tags' not in video['snippet']:\n",
    "        tags = ['none']\n",
    "    else:\n",
    "        tags = video['snippet']['tags']\n",
    "    \n",
    "\n",
    "\n",
    "    tag_embs = []\n",
    "    for tag in tags:\n",
    "        tag_embs.append(get_embeddings(tag))\n",
    "\n",
    "    tag_mean = np.mean(tag_embs, axis=0)\n",
    "\n",
    "    tt = []\n",
    "    for i in range(4):\n",
    "        if i < len(tag_embs):\n",
    "            tt.append(tag_embs[i])\n",
    "        else:\n",
    "            tt.append(np.zeros(300))\n",
    "    tt.append(tag_mean)\n",
    "    tt = np.array(tt)\n",
    "    video_data[video_id]['bigger_tags'] = tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(video_data, open('../../data/new_age/video_data', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title-short', 'title', 'tags', 'topics'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = video_data[video_id]\n",
    "v['title-short'].shape, v['title'].shape, v['tags'].shape, v['topics'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = dict()\n",
    "\n",
    "for user in users:\n",
    "    if user not in history_data:\n",
    "        # empty vectors\n",
    "        history[user]['title-short'] = np.zeros(512)\n",
    "        history[user]['title'] = np.zeros(512)\n",
    "        history[user]['tags'] = np.zeros(512)\n",
    "        history[user]['topics'] = np.zeros(512)\n",
    "        continue\n",
    "\n",
    "    history[user] = dict()\n",
    "    history[user]['title-short'] = []\n",
    "    history[user]['title'] = []\n",
    "    history[user]['tags'] = []\n",
    "    history[user]['topics'] = []\n",
    "\n",
    "    for video_id in history_data[user]:\n",
    "        history[user]['title-short'].append(video_data[video_id]['title-short'])\n",
    "        history[user]['title'].append(video_data[video_id]['title'])\n",
    "        history[user]['tags'].append(video_data[video_id]['tags'])\n",
    "        history[user]['topics'].append(video_data[video_id]['topics'])\n",
    "\n",
    "    history[user]['title-short'] = np.mean(history[user]['title-short'])\n",
    "    history[user]['title'] = np.mean(history[user]['title'])\n",
    "    history[user]['tags'] = np.mean(history[user]['tags'])\n",
    "    history[user]['topics'] = np.mean(history[user]['topics'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_path = '../../data/embeddings/channel embs/content.feather.zstd'\n",
    "reddit_path = '../../data/embeddings/channel embs/reddit.feather.zstd'\n",
    "recomm_path = '../../data/embeddings/channel embs/recomm.feather.zstd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "content = pd.read_feather(content_path)\n",
    "reddit = pd.read_feather(reddit_path)\n",
    "recom = pd.read_feather(recomm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'videos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m vid \u001b[39min\u001b[39;00m videos:\n\u001b[1;32m      2\u001b[0m     video \u001b[39m=\u001b[39m videos[vid]\n\u001b[1;32m      3\u001b[0m     asdf\n",
      "\u001b[0;31mNameError\u001b[0m: name 'videos' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "channels = []\n",
    "for vid in videos:\n",
    "    video = videos[vid]\n",
    "    cid = video['snippet']['channelId']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

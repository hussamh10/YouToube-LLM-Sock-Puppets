{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/data/hussam/sparta/youtube-sim/src/utils.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports\n",
    "import string\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from random import sample\n",
    "\n",
    "import fasttext\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "\n",
    "# reload import utils\n",
    "from importlib import reload\n",
    "reload(utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "watches = pd.read_pickle('../data/user-level-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into history and present data\n",
    "# use first 50 videos as history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = dict()\n",
    "users = list(watches.keys())\n",
    "# use first 50 watches as history\n",
    "data = dict()\n",
    "\n",
    "for user in users:\n",
    "    if len(watches[user]) < 50:\n",
    "        continue\n",
    "    history[user] = watches[user][:50]\n",
    "\n",
    "    for watch in watches[user][50:]:\n",
    "        if watch['selected'] != None:\n",
    "            if user not in data:\n",
    "                data[user] = []\n",
    "            data[user].append(watch)\n",
    "\n",
    "\n",
    "# remove users from history that are not in data\n",
    "\n",
    "for user in list(history.keys()):\n",
    "    if user not in data:\n",
    "        history.pop(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create history embeddings\n",
    "users = list(history.keys())\n",
    "\n",
    "for user in users:\n",
    "    embs = []\n",
    "    for watch in history[user]:\n",
    "        if watch['playing'] == None:\n",
    "            embs.append([0]*1536)\n",
    "        else:\n",
    "            embs.append(watch['playing']['embeddings']['title'])\n",
    "    history[user] = embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(history, open('../data/user-history-50.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(user, playing, suggested, selected):\n",
    "    if playing == None:\n",
    "        return [], []\n",
    "\n",
    "    if selected == None:\n",
    "        return [], []\n",
    "\n",
    "    if len(suggested) != 19:\n",
    "        return [], []\n",
    "\n",
    "    playing = playing['embeddings']['title']\n",
    "    Y = []\n",
    "    for s in suggested:\n",
    "        if s == None:\n",
    "            Y.append(0)\n",
    "            continue\n",
    "        id = s.get('id', None)\n",
    "        if id == selected:\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            Y.append(0)\n",
    "\n",
    "    sg = []\n",
    "    for s in suggested:\n",
    "        if s == None:\n",
    "            sg.append([0]*1536)\n",
    "            continue\n",
    "        sg.append(s['embeddings']['title'])\n",
    "    suggested = sg\n",
    "    selected = Y\n",
    "    user_history = history[user]\n",
    "\n",
    "    Y = np.array(Y).flatten()\n",
    "    playing = np.array(playing).flatten()\n",
    "    suggested = np.array(suggested)\n",
    "    user_history = np.array(user_history).flatten()\n",
    "    X = [playing, suggested, user_history]\n",
    "\n",
    "    if Y.sum() == 0:\n",
    "        return [], []\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "X, Y = [], []\n",
    "for user in users:\n",
    "    for watch in data[user]:\n",
    "        playing = watch['playing']\n",
    "        suggested = watch['suggested']\n",
    "        selected = watch['selected']\n",
    "        x, y = make_dataset(user, playing, suggested, selected)\n",
    "        if len(x) > 0:\n",
    "            X.append(x)\n",
    "            Y.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "playingX = []\n",
    "user_historyX = []\n",
    "suggestedX = []\n",
    "selectedY = []\n",
    "\n",
    "\n",
    "for x, y in zip(X, Y):\n",
    "    upnexts = x[1]\n",
    "    for i, upnext in zip(y, upnexts):\n",
    "        suggestedX.append(upnext)\n",
    "        selectedY.append(i)\n",
    "        playingX.append(x[0])\n",
    "        user_historyX.append(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40546, 1536) (40546, 76800) (40546, 1536) (40546,)\n"
     ]
    }
   ],
   "source": [
    "playingX = np.array(playingX)\n",
    "user_historyX = np.array(user_historyX)\n",
    "suggestedX = np.array(suggestedX)\n",
    "selectedY = np.array(selectedY)\n",
    "\n",
    "print(playingX.shape, user_historyX.shape, suggestedX.shape, selectedY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hussam/.local/lib/python3.6/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "playing_input = tf.keras.layers.Input(shape=(1536), name=\"playing\")\n",
    "recommendation_input = tf.keras.layers.Input(shape=(1536), name=\"recommendation\")\n",
    "history_input = tf.keras.layers.Input(shape=(76800), name=\"history_input\")\n",
    "\n",
    "playing_dense = tf.keras.layers.Dense(1024, activation=\"relu\")(playing_input)\n",
    "playing_dense = tf.keras.layers.Dropout(0.3)(playing_dense)\n",
    "playing_dense = tf.keras.layers.Dense(512, activation=\"relu\")(playing_dense)\n",
    "playing_dense = tf.keras.layers.Flatten()(playing_dense)\n",
    "\n",
    "recommendation_dense = tf.keras.layers.Dense(1024, activation=\"relu\")(recommendation_input)\n",
    "recommendation_dense = tf.keras.layers.Dropout(0.3)(recommendation_dense)\n",
    "recommendation_dense = tf.keras.layers.Dense(512, activation=\"relu\")(recommendation_dense)\n",
    "recommendation_dense = tf.keras.layers.Flatten()(recommendation_dense)\n",
    "\n",
    "history_dense = tf.keras.layers.Dense(1024, activation=\"relu\")(history_input)\n",
    "history_dense = tf.keras.layers.Dropout(0.3)(history_dense)\n",
    "history_dense = tf.keras.layers.Dense(512, activation=\"relu\")(history_dense)\n",
    "history_dense = tf.keras.layers.Dropout(0.3)(history_dense)\n",
    "history_dense = tf.keras.layers.Dense(256, activation=\"relu\")(history_dense)\n",
    "history_dense = tf.keras.layers.Flatten()(history_dense)\n",
    "\n",
    "concat = tf.keras.layers.Concatenate()([playing_dense, history_input, recommendation_dense])\n",
    "concat = tf.keras.layers.Dense(1024, activation=\"relu\")(concat)\n",
    "concat = tf.keras.layers.Dropout(0.3)(concat)\n",
    "concat = tf.keras.layers.Dense(512, activation=\"relu\")(concat)\n",
    "concat = tf.keras.layers.Dropout(0.3)(concat)\n",
    "concat = tf.keras.layers.Dense(256, activation=\"relu\")(concat)\n",
    "concat = tf.keras.layers.Dropout(0.3)(concat)\n",
    "concat = tf.keras.layers.Dense(128, activation=\"relu\")(concat)\n",
    "concat = tf.keras.layers.Dropout(0.3)(concat)\n",
    "concat = tf.keras.layers.Dense(64, activation=\"relu\")(concat)\n",
    "concat = tf.keras.layers.Dense(32, activation=\"relu\")(concat)\n",
    "concat = tf.keras.layers.Flatten()(concat)\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[playing_input, recommendation_input, history_input], outputs=output)\n",
    "\n",
    "METRICS = [keras.metrics.TruePositives(name='tp'),\n",
    "            keras.metrics.FalsePositives(name='fp'), \n",
    "            keras.metrics.TrueNegatives(name='tn'),\n",
    "            keras.metrics.FalseNegatives(name='fn'),\n",
    "            keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "            keras.metrics.Precision(name='precision'),\n",
    "            keras.metrics.Recall(name='recall'),\n",
    "            keras.metrics.AUC(name='auc'),       \n",
    "            keras.metrics.AUC(name='prc', curve='PR')]\n",
    "# import sgd\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                optimizer=sgd,\n",
    "                metrics=[METRICS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2028/2028 [==============================] - 342s 167ms/step - loss: 0.2142 - tp: 0.0000e+00 - fp: 8.0000 - tn: 30691.0000 - fn: 1737.0000 - accuracy: 0.9462 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4999 - prc: 0.0535 - val_loss: 0.2089 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 7678.0000 - val_fn: 432.0000 - val_accuracy: 0.9467 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.0533\n",
      "Epoch 2/100\n",
      " 721/2028 [=========>....................] - ETA: 3:59 - loss: 0.2092 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 10920.0000 - fn: 616.0000 - accuracy: 0.9466 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5107 - prc: 0.0541"
     ]
    }
   ],
   "source": [
    "model.fit([playingX, suggestedX, user_historyX], np.array(selectedY), epochs=100, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1268/1268 [==============================] - 23s 18ms/step - loss: 0.2091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 38377.0000 - fn: 2169.0000 - accuracy: 0.9465 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.0535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20913134515285492,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 38377.0,\n",
       " 2169.0,\n",
       " 0.9465051889419556,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.05349479615688324]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([playingX, suggestedX, user_historyX], selectedY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2134, 76800)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playingX = []\n",
    "suggestedX = []\n",
    "user_historyX = []\n",
    "\n",
    "for x in X:\n",
    "    playingX.append(x[0])\n",
    "    suggestedX.append(x[1])\n",
    "    user_historyX.append(x[2])\n",
    "\n",
    "playingX = np.array(playingX)\n",
    "suggestedX = np.array(suggestedX)\n",
    "user_historyX = np.array(user_historyX)\n",
    "\n",
    "\n",
    "print(user_historyX.shape, playingX.shape, suggestedX.shape, np.array(Y).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/hussam/miniconda3/envs/jup/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "playing_input = tf.keras.layers.Input(shape=(1536), name=\"playing\")\n",
    "recommendation_input = tf.keras.layers.Input(shape=(29184), name=\"recommendation\")\n",
    "history_input = tf.keras.layers.Input(shape=(76800), name=\"history_input\")\n",
    "\n",
    "playing_dense = tf.keras.layers.Dense(1024, activation=\"relu\")(playing_input)\n",
    "playing_dense = tf.keras.layers.Dropout(0.3)(playing_dense)\n",
    "playing_dense = tf.keras.layers.Dense(512, activation=\"relu\")(playing_dense)\n",
    "playing_dense = tf.keras.layers.Flatten()(playing_dense)\n",
    "\n",
    "recommendation_dense = tf.keras.layers.Dense(1024, activation=\"relu\")(recommendation_input)\n",
    "recommendation_dense = tf.keras.layers.Dropout(0.3)(recommendation_dense)\n",
    "recommendation_dense = tf.keras.layers.Dense(512, activation=\"relu\")(recommendation_dense)\n",
    "recommendation_dense = tf.keras.layers.Flatten()(recommendation_dense)\n",
    "\n",
    "\n",
    "history_dense = tf.keras.layers.Dense(1024, activation=\"relu\")(history_input)\n",
    "history_dense = tf.keras.layers.Dropout(0.3)(history_dense)\n",
    "history_dense = tf.keras.layers.Dense(512, activation=\"relu\")(history_dense)\n",
    "history_dense = tf.keras.layers.Flatten()(history_dense)\n",
    "\n",
    "concat = tf.keras.layers.Concatenate()([playing_dense, history_input, recommendation_dense])\n",
    "concat = tf.keras.layers.Dense(1024, activation=\"relu\")(concat)\n",
    "concat = tf.keras.layers.Dropout(0.3)(concat)\n",
    "concat = tf.keras.layers.Dense(512, activation=\"relu\")(concat)\n",
    "concat = tf.keras.layers.Dropout(0.3)(concat)\n",
    "concat = tf.keras.layers.Dense(256, activation=\"relu\")(concat)\n",
    "concat = tf.keras.layers.Dropout(0.3)(concat)\n",
    "concat = tf.keras.layers.Dense(128, activation=\"relu\")(concat)\n",
    "concat = tf.keras.layers.Dropout(0.3)(concat)\n",
    "concat = tf.keras.layers.Dense(64, activation=\"relu\")(concat)\n",
    "concat = tf.keras.layers.Dense(32, activation=\"relu\")(concat)\n",
    "concat = tf.keras.layers.Flatten()(concat)\n",
    "\n",
    "output = tf.keras.layers.Dense(19, activation=\"softmax\")(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[playing_input, recommendation_input, history_input], outputs=output)\n",
    "\n",
    "METRICS = [keras.metrics.TruePositives(name='tp'),\n",
    "            keras.metrics.FalsePositives(name='fp'), \n",
    "            keras.metrics.TrueNegatives(name='tn'),\n",
    "            keras.metrics.FalseNegatives(name='fn'),\n",
    "            keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "            keras.metrics.Precision(name='precision'),\n",
    "            keras.metrics.Recall(name='recall'),\n",
    "            keras.metrics.AUC(name='auc'),       \n",
    "            keras.metrics.AUC(name='prc', curve='PR')]\n",
    "# import sgd\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=sgd,\n",
    "                metrics=[METRICS])\n",
    "\n",
    "model.fit([playingX, suggestedX, user_historyX], np.array(Y), epochs=100, batch_size=16, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

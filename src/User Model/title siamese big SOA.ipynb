{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 16:04:41.672737: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-05 16:04:42.400499: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/hsmhabib/.conda/envs/ytbase/lib/:/home/hsmhabib/.conda/envs/ytbase/lib/python3.9/site-packages/nvidia/cudnn/lib:\n",
      "2023-09-05 16:04:42.400588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/hsmhabib/.conda/envs/ytbase/lib/:/home/hsmhabib/.conda/envs/ytbase/lib/python3.9/site-packages/nvidia/cudnn/lib:\n",
      "2023-09-05 16:04:42.400593: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sessions = pd.read_pickle('../../data/new_age/sessions')\n",
    "# history = pd.read_pickle('../../data/new_age/history')\n",
    "# videos = pd.read_pickle('../../data/new_age/video_data')\n",
    "# embeddings = pd.read_pickle('../../src/metadata & embeddings/embeddings-temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def trim(vec, element, length=15):\n",
    "    #  a vector to length and keep the element\n",
    "    if len(vec) > length:\n",
    "        vec = vec[:length]\n",
    "    if element not in vec:\n",
    "        vec = vec[:-1] + [element]\n",
    "\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history(u):\n",
    "    h = history[u]\n",
    "    title = h['title']\n",
    "    tags = h['tags']\n",
    "    topics = h['topics']\n",
    "\n",
    "    tags = np.pad(tags, (0, len(title) - len(tags)), 'constant', constant_values=0)\n",
    "    topics = np.pad(topics, (0, len(title) - len(topics)), 'constant', constant_values=0)\n",
    "\n",
    "    return np.vstack([title, tags, topics])\n",
    "\n",
    "def get_emb(video):\n",
    "    if video not in embeddings:\n",
    "        return np.zeros(384)\n",
    "    else:\n",
    "        e = embeddings[video]\n",
    "    if len(e) == 768:\n",
    "        e = e[:384]\n",
    "    return e\n",
    "\n",
    "def get_video(v):\n",
    "    title = videos[v]['title']\n",
    "    tags = videos[v]['bigger_tags'].flatten()\n",
    "    topics = videos[v]['topics']\n",
    "    transcript = get_emb(v)\n",
    "\n",
    "    # pad tags to make it the same length as title\n",
    "    tags = np.pad(tags, (0, len(title) - len(tags)), 'constant', constant_values=0)\n",
    "    topics = np.pad(topics, (0, len(title) - len(topics)), 'constant', constant_values=0)\n",
    "    transcript = np.pad(transcript, (0, len(title) - len(transcript)), 'constant', constant_values=0)\n",
    "\n",
    "    # return np.vstack([title, tags, topics])\n",
    "    return np.vstack([title, tags, topics, transcript])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# training, testing = train_test_split(sessions, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    anchor = []\n",
    "    positive = []\n",
    "    negatives = []\n",
    "\n",
    "    for i in range(14):\n",
    "        negatives.append([])\n",
    "\n",
    "    for session in data:\n",
    "        playing = session['playing']\n",
    "        selected = session['selected']\n",
    "        suggesteds = session['suggesteds']\n",
    "        user = session['user']\n",
    "        smean = []\n",
    "\n",
    "        suggesteds = trim(suggesteds, selected)\n",
    "        \n",
    "        if playing not in videos or selected not in videos or any([s not in videos for s in suggesteds]):\n",
    "            continue\n",
    "\n",
    "        h = get_history(user)\n",
    "\n",
    "\n",
    "        for i, s in enumerate(suggesteds):\n",
    "            s = get_video(s)\n",
    "            smean.append(s)\n",
    "        \n",
    "        smean = np.mean(smean, axis=0)\n",
    "\n",
    "\n",
    "        P = get_video(playing)\n",
    "        P = np.vstack([P, h, smean])\n",
    "\n",
    "        S = []\n",
    "        for i, s in enumerate(suggesteds):\n",
    "            if s != selected:\n",
    "                s = get_video(s)\n",
    "                s = np.vstack([s, h, smean])\n",
    "                # s[-1][-1] = i\n",
    "                S.append(s)\n",
    "            else:\n",
    "                Y = get_video(selected)\n",
    "                # Y[-1][-1] = i\n",
    "                Y = np.vstack([Y, h, smean])\n",
    "\n",
    "        if len(S) < 14:\n",
    "            continue\n",
    "\n",
    "        anchor.append(P)\n",
    "        positive.append(Y)\n",
    "\n",
    "        for i in range(14):\n",
    "            negatives[i].append(S[i])\n",
    "        \n",
    "    return anchor, positive, negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m anchor, positive, negatives \u001b[39m=\u001b[39m get_data(training)\n\u001b[1;32m      2\u001b[0m anchor_test, positive_test, negatives_test \u001b[39m=\u001b[39m get_data(testing)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training' is not defined"
     ]
    }
   ],
   "source": [
    "# anchor, positive, negatives = get_data(training)\n",
    "# anchor_test, positive_test, negatives_test = get_data(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import Model, metrics, layers\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import AUC, BinaryAccuracy\n",
    "from keras.layers import Dense, Dropout, Flatten, Concatenate, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, n1, n2, n3, n4, n5, n6, n7, n8, n9, n10, n11, n12, n13, n14):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an1 = tf.reduce_sum(tf.square(anchor - n1), -1)\n",
    "        an2 = tf.reduce_sum(tf.square(anchor - n2), -1)\n",
    "        an3 = tf.reduce_sum(tf.square(anchor - n3), -1)\n",
    "        an4 = tf.reduce_sum(tf.square(anchor - n4), -1)\n",
    "        an5 = tf.reduce_sum(tf.square(anchor - n5), -1)\n",
    "        an6 = tf.reduce_sum(tf.square(anchor - n6), -1)\n",
    "        an7 = tf.reduce_sum(tf.square(anchor - n7), -1)\n",
    "        an8 = tf.reduce_sum(tf.square(anchor - n8), -1)\n",
    "        an9 = tf.reduce_sum(tf.square(anchor - n9), -1)\n",
    "        an10 = tf.reduce_sum(tf.square(anchor - n10), -1)\n",
    "        an11 = tf.reduce_sum(tf.square(anchor - n11), -1)\n",
    "        an12 = tf.reduce_sum(tf.square(anchor - n12), -1)\n",
    "        an13 = tf.reduce_sum(tf.square(anchor - n13), -1)\n",
    "        an14 = tf.reduce_sum(tf.square(anchor - n14), -1)\n",
    "        return (ap_distance, an1, an2, an3, an4, an5, an6, an7, an8, an9, an10, an11, an12, an13, an14)\n",
    "\n",
    "DIM = (9, 1536)\n",
    "DP = 0.3\n",
    "\n",
    "suggested_tensor = Input(shape=DIM)\n",
    "playing_tensor = Input(shape=DIM)\n",
    "\n",
    "\n",
    "sg_dense = Dense(1024, activation='relu')(suggested_tensor)\n",
    "sg_dense = Dropout(DP)(sg_dense)\n",
    "sg_dense = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(sg_dense)\n",
    "sg = Flatten()(sg_dense)\n",
    "\n",
    "pl_dense = Dense(1024, activation='relu')(playing_tensor)\n",
    "pl_dense = Dropout(DP)(pl_dense)\n",
    "pl_dense = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(pl_dense)\n",
    "pl = Flatten()(pl_dense)\n",
    "\n",
    "merged = Concatenate()([sg, pl])\n",
    "\n",
    "d = Dense(1024, activation='relu')(merged)\n",
    "d = Dense(512, activation='relu')(d)\n",
    "d = Dropout(DP)(d)\n",
    "flatten = Flatten()(d)\n",
    "dense1 = Dense(1024, activation=\"relu\" )(flatten)\n",
    "dense1 = Dropout(DP)(dense1)\n",
    "dense1 = BatchNormalization()(dense1)\n",
    "output = Dense(512, activation=\"sigmoid\")(dense1)\n",
    "\n",
    "embedding = Model(inputs=[playing_tensor, suggested_tensor], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(Model):\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super().__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape is a context manager that records every operation that\n",
    "        # you do inside. We are using it here to compute the loss so we can get\n",
    "        # the gradients and apply them using the optimizer specified in\n",
    "        # `compile()`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        # Storing the gradients of the loss function with respect to the\n",
    "        # weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        # Let's update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        ap_distance, an1, an2, an3, an4, an5, an6, an7, an8, an9, an10, an11, an12, an13, an14  = self.siamese_network(data)\n",
    "\n",
    "        # Computing the Triplet Loss by subtracting both distances and\n",
    "        # making sure we don't get a negative value.\n",
    "        # ap_distance += 0.1\n",
    "        ans = [an1, an2, an3, an4, an5, an6, an7, an8, an9, an10, an11, an12, an13, an14]\n",
    "        losses = [ap_distance - a for a in ans]\n",
    "        loss = tf.reduce_mean(losses)\n",
    "        # loss = tf.reduce_sum(tf.reduce_mean(losses, 0.0))\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_input = Input(shape=DIM, name='anchor_p')\n",
    "selected_input = Input(shape=DIM, name='selected_p')\n",
    "n1_input = Input(shape=DIM, name='np1')\n",
    "n2_input = Input(shape=DIM, name='np2')\n",
    "n3_input = Input(shape=DIM, name='np3')\n",
    "n4_input = Input(shape=DIM, name='np4')\n",
    "n5_input = Input(shape=DIM, name='np5')\n",
    "n6_input = Input(shape=DIM, name='np6')\n",
    "n7_input = Input(shape=DIM, name='np7')\n",
    "n8_input = Input(shape=DIM, name='np8')\n",
    "n9_input = Input(shape=DIM, name='np9')\n",
    "n10_input = Input(shape=DIM, name='np10')\n",
    "n11_input = Input(shape=DIM, name='np11')\n",
    "n12_input = Input(shape=DIM, name='np12')\n",
    "n13_input = Input(shape=DIM, name='np13')\n",
    "n14_input = Input(shape=DIM, name='np14')\n",
    "\n",
    "distances = DistanceLayer()(\n",
    "    embedding([anchor_input, anchor_input]),\n",
    "    embedding([anchor_input, selected_input]),\n",
    "    embedding([anchor_input, n1_input]),\n",
    "    embedding([anchor_input, n2_input]),\n",
    "    embedding([anchor_input, n3_input]),\n",
    "    embedding([anchor_input, n4_input]),\n",
    "    embedding([anchor_input, n5_input]),\n",
    "    embedding([anchor_input, n6_input]),\n",
    "    embedding([anchor_input, n7_input]),\n",
    "    embedding([anchor_input, n8_input]),\n",
    "    embedding([anchor_input, n9_input]),\n",
    "    embedding([anchor_input, n10_input]),\n",
    "    embedding([anchor_input, n11_input]),\n",
    "    embedding([anchor_input, n12_input]),\n",
    "    embedding([anchor_input, n13_input]),\n",
    "    embedding([anchor_input, n14_input]),\n",
    ")\n",
    "\n",
    "siamese_network = Model(\n",
    "    inputs = [anchor_input, selected_input, n1_input, n2_input, n3_input, n4_input, n5_input, n6_input, n7_input, n8_input, n9_input, n10_input, n11_input, n12_input, n13_input, n14_input],\n",
    "    outputs=distances\n",
    ")\n",
    "\n",
    "siamese_model = SiameseModel(siamese_network)\n",
    "# siamese_model.compile()\n",
    "siamese_model.compile(optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anchor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m anchornp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(anchor)\n\u001b[1;32m      2\u001b[0m positivenp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(positive)\n\u001b[1;32m      3\u001b[0m negativesnp \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39marray(n) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m negatives]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'anchor' is not defined"
     ]
    }
   ],
   "source": [
    "anchornp = np.array(anchor)\n",
    "positivenp = np.array(positive)\n",
    "negativesnp = [np.array(n) for n in negatives]\n",
    "\n",
    "anchornp_test = np.array(anchor_test)\n",
    "positivenp_test = np.array(positive_test)\n",
    "negativesnp_test = [np.array(n) for n in negatives_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN = [anchornp, positivenp, negativesnp]\n",
    "# pkl.dump(TRAIN, open('test-temp.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN, open('test-temp.pkl', 'wb'))\n",
    "[anchornp, positivenp, negativesnp] = pd.read_pickle('test-temp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "916/916 [==============================] - 140s 149ms/step - loss: 0.6000 - val_loss: 0.5999\n",
      "Epoch 2/120\n",
      "916/916 [==============================] - 28s 30ms/step - loss: 0.6000 - val_loss: 0.5999\n",
      "Epoch 3/120\n",
      "916/916 [==============================] - 27s 29ms/step - loss: 0.6000 - val_loss: 0.5999\n",
      "Epoch 4/120\n",
      "916/916 [==============================] - 27s 30ms/step - loss: 0.6000 - val_loss: 0.5999\n",
      "Epoch 5/120\n",
      "916/916 [==============================] - 27s 30ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 6/120\n",
      "916/916 [==============================] - 27s 30ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 7/120\n",
      "916/916 [==============================] - 28s 30ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 8/120\n",
      "916/916 [==============================] - 27s 29ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 9/120\n",
      "916/916 [==============================] - 27s 30ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 10/120\n",
      "916/916 [==============================] - 27s 30ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 11/120\n",
      "916/916 [==============================] - 28s 31ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 12/120\n",
      "916/916 [==============================] - 28s 30ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 13/120\n",
      "916/916 [==============================] - 28s 31ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 14/120\n",
      "916/916 [==============================] - 27s 30ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 15/120\n",
      "916/916 [==============================] - 28s 30ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 16/120\n",
      "916/916 [==============================] - 28s 30ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 17/120\n",
      "916/916 [==============================] - 28s 30ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 18/120\n",
      "916/916 [==============================] - 27s 30ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 19/120\n",
      "916/916 [==============================] - 27s 29ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 20/120\n",
      "916/916 [==============================] - 27s 30ms/step - loss: 0.5999 - val_loss: 0.5999\n",
      "Epoch 21/120\n",
      "916/916 [==============================] - ETA: 0s - loss: 0.5999"
     ]
    }
   ],
   "source": [
    "siamese_model.fit([anchornp, positivenp] + negativesnp, batch_size=8, epochs=120, validation_split=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese_model.evaluate([anchornp_test, positivenp_test] + negativesnp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = embedding([anchornp_test, anchornp_test])\n",
    "p = embedding([anchornp_test, positivenp_test])\n",
    "ns = []\n",
    "\n",
    "for i in range(14):\n",
    "    ns.append(embedding([anchornp_test, negativesnp_test[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tp = 0\n",
    "tn = 0\n",
    "total = 0\n",
    "ranks = []\n",
    "\n",
    "lens = len(anchornp_test)\n",
    "\n",
    "for i in range(lens):\n",
    "    at = np.array(a[i])\n",
    "    pt = np.array(p[i])\n",
    "    nst = [np.array(ns[j][i]) for j in range(14)]\n",
    "\n",
    "    pv = cosine_similarity(at.reshape(1, -1), pt.reshape(1, -1)).flatten()[0]\n",
    "    nvs = [cosine_similarity(at.reshape(1, -1), nst[j].reshape(1, -1)).flatten()[0] for j in range(14)]\n",
    "\n",
    "    sims = [pv] + nvs\n",
    "    simnv = nvs\n",
    "\n",
    "    sims.sort(reverse=True)\n",
    "    rank = sims.index(pv) + 1\n",
    "    ranks.append(rank)\n",
    "\n",
    "    if pv > np.max(simnv):\n",
    "        tp += 1\n",
    "    else:\n",
    "        tn += 1\n",
    "\n",
    "\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12078346028291621"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4600.,  843., 1027.,  911., 1323., 1260.,  686.,  946.,  754.,\n",
       "         695.,  905., 1201., 1323.,  606., 1050.]),\n",
       " array([ 0.        ,  0.93333333,  1.86666667,  2.8       ,  3.73333333,\n",
       "         4.66666667,  5.6       ,  6.53333333,  7.46666667,  8.4       ,\n",
       "         9.33333333, 10.26666667, 11.2       , 12.13333333, 13.06666667,\n",
       "        14.        ]),\n",
       " <BarContainer object of 15 artists>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = np.random.random(13)\n",
    "k = np.random.random(13) * 10\n",
    "r = r + k + 3\n",
    "# r = sorted(r, reverse=True)\n",
    "\n",
    "import numpy as np\n",
    "ranks = [0] * 4600\n",
    "for i in range(14):\n",
    "    ranks+= [i+1] * int(r[i] * 100)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.hist(ranks, bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
